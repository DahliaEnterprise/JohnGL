<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Trails</title>
  <script type="text/javascript">
		/* SHADER SOURCE CODE */
		var solid_color_vertex_shader_source_code = "";
        solid_color_vertex_shader_source_code = solid_color_vertex_shader_source_code + "attribute vec4 position_of_vertex_to_colorize; \n";
        solid_color_vertex_shader_source_code = solid_color_vertex_shader_source_code + "attribute vec4 color_of_vertex_to_colorize; \n";
        solid_color_vertex_shader_source_code = solid_color_vertex_shader_source_code + "varying vec4 varying_color_of_vertex_to_colorize; \n";
        solid_color_vertex_shader_source_code = solid_color_vertex_shader_source_code + "void main() { \n";
        solid_color_vertex_shader_source_code = solid_color_vertex_shader_source_code + "  //colorize position.  \n";
        solid_color_vertex_shader_source_code = solid_color_vertex_shader_source_code + "  gl_Position = position_of_vertex_to_colorize; \n";
        solid_color_vertex_shader_source_code = solid_color_vertex_shader_source_code + "  varying_color_of_vertex_to_colorize = color_of_vertex_to_colorize;  \n";
        solid_color_vertex_shader_source_code = solid_color_vertex_shader_source_code + "} \n";
     
		var solid_color_fragment_shader_source_code = "";
				solid_color_fragment_shader_source_code = solid_color_fragment_shader_source_code + "precision mediump float;  \n";
        solid_color_fragment_shader_source_code = solid_color_fragment_shader_source_code + "varying vec4 varying_color_of_vertex_to_colorize; \n";
        solid_color_fragment_shader_source_code = solid_color_fragment_shader_source_code + "void main() { \n";
        solid_color_fragment_shader_source_code = solid_color_fragment_shader_source_code + "  //Define filter \n";
        solid_color_fragment_shader_source_code = solid_color_fragment_shader_source_code + "  gl_FragColor = varying_color_of_vertex_to_colorize; \n";
        solid_color_fragment_shader_source_code = solid_color_fragment_shader_source_code + "} \n";
										
		 var list_of_shaders_names = ["solid_color_vertex"];//only useful for turning all on or turning all off(to be clear, freeing memory for scenes that only need a particular aset of shaders to be used).
	   var list_of_shaders_jsonobjects = {
			                                   "solid_color_vertex": {
															                                   "vertex_sourcecode": solid_color_vertex_shader_source_code,
																										             "fragment_sourcecode": solid_color_fragment_shader_source_code,
																										             "program_is_available":false
															                                  }
			                                 };
		
    /* MODELS SOURCE CODE */
    var one_by_one_ratio_square_model_source_code = {
                                                "coordinated_space_positions": "1013760, 1013761, 1013760, 1013759, 1013761, 1013760, 1013759, 1013760, 1013760",
                                                "opengl_color_values": "1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0",
                                                "shader_program": "solid_color_vertex"
                                              };
                                       
    /* GLOBAL VARIABLES */
      /* Functions as variables */
			/* Format: base identifier, specific purpose or subset identifer, purpose description(most function names may not be this long and or descriptive) */
        /* Startup */
        var begin_startup = null;
        var stage_one = null;
        var stage_two = null;
				
				/* Shader */
				var shader_compile_shader = null;
				var shader_freememory_and_load_relevant_shaders = null;

				/* Course of actions loop */
        var course_of_actions_synchronized_timestamp = null;
        var course_of_actions_synchronized_timepassed_since_last_run = null;
        
        var course_of_actions_ticks_per_second = null;
        
        var course_of_actions_target_loop_interval = null;
        var course_of_actions_cooldown_time = null;
        
			  var course_of_actions_loop = null;
				
				/* User Land Logic */
        var userland_syncronized_timestamp = null;
        var userland_syncronized_timepassed_since_last_run = null;
        
				var userland_scene_majorscene = null;
				var userland_scene_prestage_to_majorscene = null;
				var userland_scene_microscene_of_majorscene = null;
        
        var userland_scene_models = {};
        
        var userland_camera = {};
        
				var userland_course_of_actions_pulse = null;
        var userland_scene_models_append_copy_of_model = null;
				
        /* Draw Screen Loop */
        var drawscreenloop_render_syncronized_timestamp = null;
        var drawscreenloop_render_syncronized_timepassed_since_last_run = null;
        
        var drawscreenloop_render_select_lastid_used = null;
        var drawscreenloop_render_selection = [];
        
        var drawscreenloop_intrim_array_of_buffers = [];
        
				var drawscreenloop_render_screen = null;
				
        
      /* Synchronous Variables */
      const synchronous_decimal_fraction_precision = 6;
    
      /* Open GL ES */
        /* HTML Elements */
        var canvas_for_opengl = null;

        /* Interface */
        var interface_to_opengles = null;

        /* Inline Shaders */
        var list_of_shaders = [];

        /* List of models */
        var list_of_models = {};

      /* Imperial Measurment */
      var imperial_measurement = {};
    
      /* Coordinated Space */
      var coordinated_space = {};
      
      var coordinated_space_convert_xyz_to_opengl_viewport_xyz = null;
    
    /* Stage One, Initialize Handles */
    stage_one = function()
    {
      //Initialize canvas handle and interface to opengl handle.
      canvas_for_opengl = document.getElementById("canvas_for_opengl");
      interface_to_opengles = canvas_for_opengl.getContext("webgl2");
      
      //Set width and height of canvas intended for OpenGL rendering.
      canvas_for_opengl.style.width = "500px";
      canvas_for_opengl.style.height = "500px";
      
      //notify opengles hardware the size of the canvas by setting the viewport.
      interface_to_opengles.viewportWidth = canvas_for_opengl.width;
      interface_to_opengles.viewportHeight = canvas_for_opengl.height;
        
   
    }

    /* Stage Two, 
         Define coordinated space, 
         list of shaders and models, 
         course of actions syncronized timestamp
         User land states 
    */
    stage_two = function()
    {
      /* Define Imperial Measurement */
      imperial_measurement["unit_type"] = "inches";
      
      imperial_measurement["total_hatchmarks_per_one_inch"] = 32;
      imperial_measurement["size_of_space_between_hatchmark"] = 0.031250;//inches.
      
      imperial_measurement["diameter_of_one_unitedstates_quarter"] = 0.955000;//inches.
      imperial_measurement["length_of_one_mile"] = 63360.000000; //one mile is 5280 feet, 5280 feet muliplied by 12 inches(one foot) is 63360 inches exactly.

      
      /* Coordinated Space Definition */
          /* Length of plane */
          coordinated_space["length_of_x_plane_hatchmarks"] = (imperial_measurement["length_of_one_mile"] * imperial_measurement["total_hatchmarks_per_one_inch"]);
          coordinated_space["length_of_y_plane_hatchmarks"] = (imperial_measurement["length_of_one_mile"] * imperial_measurement["total_hatchmarks_per_one_inch"]);
          coordinated_space["length_of_z_plane_hatchmarks"] = (imperial_measurement["length_of_one_mile"] * imperial_measurement["total_hatchmarks_per_one_inch"]);
          
          /* Center of plane */
          coordinated_space["center_of_x_plane_hatchmarks"] = Math.trunc((coordinated_space["length_of_x_plane_hatchmarks"] / 2));
          coordinated_space["center_of_y_plane_hatchmarks"] = Math.trunc((coordinated_space["length_of_y_plane_hatchmarks"] / 2));
          coordinated_space["center_of_z_plane_hatchmarks"] = Math.trunc((coordinated_space["length_of_z_plane_hatchmarks"] / 2));
					
      /* Course of actions */
      course_of_actions_synchronized_timestamp = Date.now();
      course_of_actions_ticks_per_second = 60;
      course_of_actions_target_loop_interval = (1000 / (60 * 10)); //60 ticks per second multiplied by ten(to keep up and or be ahead of any drift that may occur within motion or physics systems).
      course_of_actions_cooldown_time = 1;
      
			/* User Land States */
      userland_syncronized_timestamp = Date.now();
			userland_scene_majorscene = 1;
			userland_scene_prestage_to_majorscene = 1;
			userland_scene_microscene_of_majorscene = 1;
			userland_camera["position"] = {
                                      "x": coordinated_space["center_of_x_plane_hatchmarks"],
                                      "y": coordinated_space["center_of_y_plane_hatchmarks"],
                                      "z": coordinated_space["center_of_z_plane_hatchmarks"]
                                    };
      userland_camera["rotation"] = {
                                      "x": 0.000000,
                                      "y": 0.000000,
                                      "z": 0.000000
                                    };
      
      /* Draw screen loop */
      drawscreenloop_render_syncronized_timestamp = Date.now();
      drawscreenloop_render_select_lastid_used = 0;
    }
		
		/* Shader */
		shader_compile_shader = function(vertex_shader_sourcecode, fragment_shader_sourcecode)
		{
			let output = null;
			  
        //compile vertex shader source code
		  	let vertex_shader_of_program = interface_to_opengles.createShader(interface_to_opengles.VERTEX_SHADER);
          
        interface_to_opengles.shaderSource(vertex_shader_of_program, vertex_shader_sourcecode);
        interface_to_opengles.compileShader(vertex_shader_of_program);

        if(interface_to_opengles.getShaderParameter(vertex_shader_of_program, interface_to_opengles.COMPILE_STATUS) == false)
        {
          console.log("vertex shader failed to compile ()");
        }

        //compile fragment shader source code
        let fragment_shader_of_program = interface_to_opengles.createShader(interface_to_opengles.FRAGMENT_SHADER);
          
	  	  interface_to_opengles.shaderSource(fragment_shader_of_program, fragment_shader_sourcecode );
        interface_to_opengles.compileShader(fragment_shader_of_program);

        if(interface_to_opengles.getShaderParameter(fragment_shader_of_program, interface_to_opengles.COMPILE_STATUS) == false)
        {
         console.log("fragment shader failed to compile (_fragment)");
            
        }
			
        //link vertex shader and fragment shader to a shader program.
        let linked_shader_program = interface_to_opengles.createProgram();
        interface_to_opengles.attachShader(linked_shader_program, vertex_shader_of_program);
        interface_to_opengles.attachShader(linked_shader_program, fragment_shader_of_program);
        interface_to_opengles.linkProgram(linked_shader_program);
        
        if(!interface_to_opengles.getProgramParameter(linked_shader_program, interface_to_opengles.LINK_STATUS))
        {
          console.log("shader link process failed.");
        }
        
	  		output = linked_shader_program;
			return output;
		}
		
		shader_freememory_and_load_relevant_shaders = function(list_of_shader_names_to_be_available)
		{
      //not a reentrant function.(single threaded application intended to be converted to multithreaded).
      for(let list_of_shaders_jsonobject_key in list_of_shaders_jsonobjects)
      {
        //fault preventention
        if(list_of_shaders_jsonobjects.hasOwnProperty(list_of_shaders_jsonobject_key) == true)
        {
          //free from memory or "compile and allocate into memory"?
          let name_of_shader_within_list_of_shaders_jsonobject = list_of_shaders_jsonobject_key;
          let exists_within_list_of_shaders_to_be_available = list_of_shader_names_to_be_available.includes(name_of_shader_within_list_of_shaders_jsonobject);
          if(exists_within_list_of_shaders_to_be_available == true)
          {
            if(list_of_shaders_jsonobjects[""+name_of_shader_within_list_of_shaders_jsonobject]["program_is_available"] == false)
            {
              //compile and allocate into memory if not already compiled and allocated into memory.
              let vertex_sourcecode = list_of_shaders_jsonobjects[""+name_of_shader_within_list_of_shaders_jsonobject]["vertex_sourcecode"];
              let fragment_sourcecode = list_of_shaders_jsonobjects[""+name_of_shader_within_list_of_shaders_jsonobject]["fragment_sourcecode"];
                //do compile
                let shader_program = shader_compile_shader(vertex_sourcecode, fragment_sourcecode);
            
                //do allocate shader program to list of shaders jsonobject memory
                list_of_shaders[""+name_of_shader_within_list_of_shaders_jsonobject] = shader_program;
                
                //do change "program is available" flag to true.
                list_of_shaders_jsonobjects[""+name_of_shader_within_list_of_shaders_jsonobject]["program_is_available"] = true;
                
            }
          }else if(exists_within_list_of_shaders_to_be_available == false)
          {
            //do free from memory it is currently not going to be used.
              //note: make null instead of splice as this will prevent a copying algorithm; doubly useful to keep null instead of delete for fast placement when the shader is needed again, reducing the need to envoke a copy algorithim.
              list_of_shaders[""+name_of_shader_within_list_of_shaders_jsonobject] = null;
            
            //do change "program is available" flag to false.
            list_of_shaders_jsonobjects[""+name_of_shader_within_list_of_shaders_jsonobject]["program_is_available"] = false;
            
          }
        }
      }
		}
		
		/* Course of Actions Loop */
		course_of_actions_loop = function()
		{
      //Determine time passed since last course of actions ran.
      course_of_actions_synchronized_timepassed_since_last_run = Date.now() - course_of_actions_synchronized_timestamp;
      
			//User Land Logic
			userland_course_of_actions_pulse();
			
			//render screen
			drawscreenloop_render_screen();
      
			//envoke course of actions loop.
      let milliseconds_from_now = 1;
      if(course_of_actions_synchronized_timepassed_since_last_run > course_of_actions_target_loop_interval)
      {
        //set to timer to now plus cooldown time.
        milliseconds_from_now = course_of_actions_cooldown_time;
        
      }else if(course_of_actions_synchronized_timepassed_since_last_run <= course_of_actions_target_loop_interval)
      {
        //set timer to remaining time of execution time minus "course of actions target loop interval"
        milliseconds_from_now = course_of_actions_target_loop_interval - course_of_actions_synchronized_timepassed_since_last_run;
        if(milliseconds_from_now < course_of_actions_cooldown_time)
        {
          milliseconds_from_now = course_of_actions_cooldown_time;
        }
      }
    
      //course of actions is completed, set syncronized timestamp.
      course_of_actions_synchronized_timestamp = Date.now();
			
      //envoke course of actions at the designated time.
			setTimeout(course_of_actions_loop, milliseconds_from_now);
		}
		
		/* User Land Logic */
		userland_course_of_actions_pulse = function()
		{
      //Determine time passed since last "user land course of actions pulse" ran.
      userland_syncronized_timepassed_since_last_run = Date.now() - userland_syncronized_timestamp;
      
			/* 
			   Guidelines of
			   Prestage Scene, Major Scene, Minor Scene
				 
			   Every major scene has one successive
				 prestage. Once all prestages have been satisfied
				 then the microscenes will coordinate toggling
				 on or off by switching microscenes based on
				 events of the user or events within the application.
				 Major scenes also switch based on user interactions or events
				 from the application. 
				 
				 Although the prestage, microscene, and majorscene
				 are clearly defined they are so defined as such
				 to cooperate with the shader and model memory management
				 model and is also in line with real world artist workflow
				 with working with groups of flip books or video scenes;
				 That being said, aslong as one does not have logic outside a major
				 scene code block almost any rendering workflow within regards to
				 logic can be accepted with out being disruptive to the
				 operator of the application.
			*/
			if(userland_scene_majorscene == 1)
			{
				if(userland_scene_prestage_to_majorscene == 1)
			  {
					//begin coordinating the compilations of shaders and notifying the operator of the progress(loading bar)
          shader_freememory_and_load_relevant_shaders(["solid_color_vertex"]);
          
          //copy the "one to one ratio square" model to be used in the userland scene models.
          userland_scene_models_append_copy_of_model("loading_background_image_placeholder", one_by_one_ratio_square_model_source_code["coordinated_space_positions"], one_by_one_ratio_square_model_source_code["opengl_color_values"], one_by_one_ratio_square_model_source_code["shader_program"]);
          
          //temporarily activate scaling algorithm.
          userland_scene_models["loading_background_image_placeholder"]["scale"]["x"] = 0.5;
          
          //show loading screen, while asyncrounously compiling english and number models.
          userland_scene_prestage_to_majorscene = 2;
        }else if(userland_scene_prestage_to_majorscene == 2)
        {
          //append a loading screen image to drawscreen list.
          drawscreenloop_render_selection.push("loading_background_image_placeholder");
          
          //append a loading bar image to drawscreen list.
          
          //no textual updates will occur here only loading animation bar.
          
		    }else if(userland_scene_prestage_to_majorscene == 0)
				{
					/* the major scene is now activated and prestage scene(s) are not active, 
					   this is where the microscene(s) can be toggled amongst each other
						 based on user events or application events.
						 The developer is free to design the touch screen
						 events in any way desired within the microscene and
						 between toggling of microscenes as long the developer
						 and developers ensure a selected paradigm across
						 microscenes that rely on eachother.
					*/
				  if(userland_scene_microscene_of_majorscene == 1)
					{
						//begin first user land interaction or animation here.
					}
				}
			}
      
      //User land set syncronized timestamp.
      userland_syncronized_timestamp = Date.now();
		}
    
    userland_scene_models_append_copy_of_model = function(name_of_model_to_be_listed_within_userland_scene_models, coordinated_space_positions, opengl_color_values, name_of_shader_program)
    {
      //initialize userland model.
      let userland_model = {};
        //vertex
        userland_model["vertex"] = {};
        //orientation
        userland_model["orientation"] = {};
        //scale
        userland_model["scale"] = {};
        //name of shader program
        userland_model["name_of_shader_program"] = "";
        
      //copy model source code to userland model. (purpose: the source code can be reused to establish different formats and or have a zeroed rotation and position to copy from before translations(reduces drift).
      userland_model["vertex"]["coordinated_space_positions"] = coordinated_space_positions;
      userland_model["vertex"]["opengl_color_values"] = opengl_color_values;
      
      //initialize orientation of model within the coordinated space.
      userland_model["orientation"]["rotation_x"] = 0.000000;
      userland_model["orientation"]["rotation_y"] = 0.000000;
      userland_model["orientation"]["rotation_z"] = 0.000000;
      userland_model["orientation"]["position_x"] = coordinated_space["center_of_x_plane_hatchmarks"];
      userland_model["orientation"]["position_y"] = coordinated_space["center_of_y_plane_hatchmarks"];
      userland_model["orientation"]["position_z"] = coordinated_space["center_of_z_plane_hatchmarks"];
      
      //initialize scale of model
      /* since the model paradigms are intended only 
         to be complex when interconnected in any way 
         shape or form with other models, a "super model",
         the scale is not given any complex parameters
         in order to achieve granular control per model
         defined by the artist and or developer(s). 
         An example of its common useage would be to
         scale down the largest available size of the original
         model data during the development process.
         the artist and or developers would alter the 
         userland model scale parameters until the x,y,z
         scales are within their intended real world sizes
         using the hatchmarks measurements to determine those
         sizes have been achieved digitally within relationship
         to the artists and or developers comprehension of the
         real world model.
      */
      
      /* one exactly is the size of the artists 
         and or moddlers and or developers inputted
         vertices positions, smaller than one will shrink
         the model(this will likely occur often), while
         a number larger than one will expand the model.
      */
      userland_model["scale"]["x"] = 1.000000;
      userland_model["scale"]["y"] = 1.000000;
      userland_model["scale"]["z"] = 1.000000;
      
      
      //define the name of shader program to be used for this model.
      userland_model["name_of_shader_program"] = name_of_shader_program;
      
      //copy to userland scene models.
      userland_scene_models[""+name_of_model_to_be_listed_within_userland_scene_models] = userland_model;
    }
    
    /* Draw Screen Loop */
	  drawscreenloop_render_screen = function()
		{
      //Determine time passed since last "draw screen loop render screen" ran.
      drawscreenloop_render_syncronized_timepassed_since_last_run = Date.now() - drawscreenloop_render_syncronized_timestamp;
			
      //order of operations here.
        //Clear the viewport(screen) before drawing a new frame. (you will always do it this way, the only rare times you will add on to an already drawn frame is maybe an Operating System window(or UI) that goes on top of everything else and usually only when there is no alpha or moving objects).
        interface_to_opengles.clearColor(0.0, 0.0, 0.0, 1.0);
        interface_to_opengles.viewport(0, 0, interface_to_opengles.viewportWidth, interface_to_opengles.viewportHeight);
        interface_to_opengles.clear(interface_to_opengles.COLOR_BUFFER_BIT | interface_to_opengles.DEPTH_BUFFER_BIT);
        
        //Enable depth test(enables depth of objects within rendering).
        interface_to_opengles.enable(interface_to_opengles.DEPTH_TEST);
      
        //intrim array of OpenGL buffer(s).
        drawscreenloop_intrim_array_of_buffers = [];
        
        //render each model declared within the drawscreenloop render selection.
        for(let index = 0; index < drawscreenloop_render_selection.length; index = index + 1)
        {
          //aquire handle.
          let handle_of_model_within_userland_space = userland_scene_models[""+drawscreenloop_render_selection[index]];
          
          //split string vertex coordinated positions into Float32Array.
            //to do: keep this data as float32array(instead of string format) before it touches the draw function.
            //split string per comma.
            let vertex_coordinated_positions_string_split = handle_of_model_within_userland_space["vertex"]["coordinated_space_positions"].split(",");
            //create empty float32array for integers of vertex coordinated positions.
            let vertex_coordinated_positions_float32array = new Float32Array(vertex_coordinated_positions_string_split.length);
            //fill integers(from string) into vertex coordinated positions float32array.
            for(let vertex_coordinated_positions_string_split_index = 0; vertex_coordinated_positions_string_split_index < vertex_coordinated_positions_string_split.length; vertex_coordinated_positions_string_split_index = vertex_coordinated_positions_string_split_index + 1){ vertex_coordinated_positions_float32array[vertex_coordinated_positions_string_split_index] = parseInt(vertex_coordinated_positions_string_split[vertex_coordinated_positions_string_split_index]); }
          
           //split string vertex color values into Float32Array.
            //to do: keep this data as float32array(instead of string format) before it touches the draw function.
            //split string per comma.
            let vertex_color_values_string_split = handle_of_model_within_userland_space["vertex"]["opengl_color_values"].split(",");
            //create empty float32array for integers of opengl color values.
            let vertex_color_values_float32array = new Float32Array(vertex_color_values_string_split.length);
            //fill integers(from string) into vertex color values float32array.
            for(let vertex_color_values_string_split_index = 0; vertex_color_values_string_split_index < vertex_color_values_string_split.length; vertex_color_values_string_split_index = vertex_color_values_string_split_index + 1){ vertex_color_values_float32array[vertex_color_values_string_split_index] = parseInt(vertex_color_values_string_split[vertex_color_values_string_split_index]); }
            
          /* note: as a reminder, coordinated space 
                   is used for the ease of mind of the
                   developer which will usually result in less 
                   communication barriers with the artists intentions
                   , this also includes story boards presented by the producers
                   and anyone else involved with the decision making of
                   the intended experience of the graphics application.
          */
          //compile vertex positions and color values into a block interlaced array(convert coordinated space to opengl positional values).
            //initialize Float32Array
            let vertex_and_colorvalues_data = new Float32Array((vertex_coordinated_positions_float32array.length+vertex_color_values_float32array.length));
            //console.log(vertex_and_colorvalues_data);
            //do compile.
            let compile_vertex_index = 0;
            let compile_colorvalues_index = 0;
            let vertex_and_colorvalues_data_index = 0;
            let continue_compiling = 1;
            while(continue_compiling == 1)
            {
              //define next block of vertex values and color values.
                //convert coordinated space to opengl positions(assume there is no camera other than the default opengl window/viewport for now).
                let opengl_positions = coordinated_space_convert_xyz_to_opengl_viewport_xyz(vertex_coordinated_positions_float32array[compile_vertex_index], vertex_coordinated_positions_float32array[compile_vertex_index+1], vertex_coordinated_positions_float32array[compile_vertex_index+2]);
                
                //coordinated space
                vertex_and_colorvalues_data[vertex_and_colorvalues_data_index] = opengl_positions["x"];
                vertex_and_colorvalues_data[vertex_and_colorvalues_data_index+1] = opengl_positions["y"];
                vertex_and_colorvalues_data[vertex_and_colorvalues_data_index+2] = opengl_positions["z"];
                
                //color values
                vertex_and_colorvalues_data[vertex_and_colorvalues_data_index+3] = vertex_color_values_float32array[compile_colorvalues_index];
                vertex_and_colorvalues_data[vertex_and_colorvalues_data_index+4] = vertex_color_values_float32array[compile_colorvalues_index+1];
                vertex_and_colorvalues_data[vertex_and_colorvalues_data_index+5] = vertex_color_values_float32array[compile_colorvalues_index+2];
                vertex_and_colorvalues_data[vertex_and_colorvalues_data_index+6] = vertex_color_values_float32array[compile_colorvalues_index+3];
                
                
              //iterate for next block to copy.
              vertex_and_colorvalues_data_index = vertex_and_colorvalues_data_index + 7;
              compile_vertex_index = compile_vertex_index + 3;
              compile_colorvalues_index = compile_colorvalues_index + 4;
              
              //stop loop?
              if(vertex_and_colorvalues_data_index >= vertex_and_colorvalues_data.length)
              {
                //stop
                continue_compiling = 0;
              }
            }
          //  console.log(vertex_and_colorvalues_data)
            
            /* order of operations is
             rotate, scale, position.
             
             ROTATION
             rotate before you position because its presumed that most times
             your object will already be centered during initial model (down)load.
             if not positioned at the center-point of the (universally defined)
             center point of vertex coordinated space(which is the same parameters
             as object/model/world coordinated space) rotation can be applied to
             a known(within context of "capable with precision") custom defined center point
             with out the need for complex logic(which can result in chaos and that is against the mission)
             to determine how to deal with the result, had the rotation been applied with out a precisly
             known custom defined center point(the object is tight or 
             loose within a scene due to game events or user interaction)
             (making the possibilities easier on the mind (in retrospect) to be inline with any
             programmers mind set).
             
             rotate before you scale because although the 
             rotation computations are equal in
             speed (and difficulty) regardless of 
             the scale of the objects vertices(and points), the placement of
             points will be more accurate when rotated vertices(points) 
             are quantized to the digital grid(coordinated space resolution) when applied
             at the moddlers/developers inputted original size(placement of points),
             as it is presumed the object will be modeled at its largest size during (down)load
             from the artists/moddler/developers inputted vertices(positions).
             to be clear, large is not the defining attribute, as any
             small vertices(on a scale of coordinated space and a quarter dollar)
             can be scaled large, its when a model is inputted by the artist/moddler/developer
             at large or extremly large sizes for example a dollar bill is inputted/moddeled
             at the size of one mile length ways(the maximum size in a universally defined world coordinated space)
             and then the scale size(seen in the next step) is set to produce the most precise
             scaling calculations as it is given a higher resolution to work with to produce
             a scaled down or scaled up version of actual real world size in side the digital world.
             Excerpt: this is the digital model implementation of scanning a highest resolution paper photo
                      for the purposes of scaling down or scaling up; experience would determine that 
                      scanning a low resolution photo and scaling down makes it blury(although smaller)
                      where as scanning a high resolution photo and scaling down makes it as clear
                      and legiable as possible while achieving the smaller size.
             
             
             SCALE
             scale before positioning the objects vertices(points)
             in order to prevent interjection/events/hooks paradigms 
             between scale and positioning at the only negative trade off being vertice(points) placement 
             during quantaization of the placement of scaled vertices(points) 
             on the coordinated space(hatch marks) with (probably unoticable, one more or less hatchmark) inaccuraccies.
             This will envoke a sense of incentivization of less work by the developer/programmers
             altering the object/model only after scale and positioning have completed,
             there by resulting in physics,events,user interactions being placed within
             a pipeline paradigm(predictable putcomes due to nonchanging order of operations)
             and thus keeping the "events by decision tree" paradigm and making "events by triggering mechenism"
             paradigm (more than likely apparentness)break at runtime of the program with out the need of a monitoring program or human
             to enforce the events by decision tree paradign and likewise enforce against the events by triggerung mechinisms paradigm.
             
             POSITION
             position is last. positioning will succum to
             quantized accuracies although will have the
             maximized minimization of inaccuracies when rotation
             and scale are applied as defined above.
          */
          //Apply rotation
            //to-do: make rotation applied by pointing each axis to a point this will prevent an erractic rotations during animation and will not need to switch orders of rotation in order to prevent erratic rotation and prevent rotation inaccuracies(to be clear: this will enforce reproduceable rotations).
            //Rotation Z
              //determine if rotation should be applied(strictly a cpu time saver).
               if((handle_of_model_within_userland_space["orientation"]["rotation_z"]*1000000) != 0)
               {
                 //do apply rotation.
               }
          //Apply scale.
            //use a scaling algorithm that is the likeness of square transformations as opposed to the alternative, circle area transformations.
            //determine if scaling should be applied(strictly a cpu time saver).
            let is_scale_not_one_to_one_ratio = 0;
            if((handle_of_model_within_userland_space["scale"]["x"]*1000000) != 1000000)
            {
             is_scale_not_one_to_one_ratio = 1;
            }else if((handle_of_model_within_userland_space["scale"]["y"]*1000000) != 1000000)
            {
             is_scale_not_one_to_one_ratio = 1;
            }else if((handle_of_model_within_userland_space["scale"]["z"]*1000000) != 1000000)
            {
             is_scale_not_one_to_one_ratio = 1;
            }
            
            if(is_scale_not_one_to_one_ratio == 1)
            {
              //do apply scale.
              vertex_and_colorvalues_data_index = 0;
              let continue_applying_scale = 1;
              while(continue_applying_scale == 1)
              {
                //apply x scale.
                let x_scale = 1.000000;
                let prevent_loss_of_precision_during_useage_of_zero = 0;
                if((handle_of_model_within_userland_space["scale"]["x"]*1000000) == 0)
                {
                 prevent_loss_of_precision_during_useage_of_zero = 1;
                }
                
                if(prevent_loss_of_precision_during_useage_of_zero == 1)
                {
                  //ensures data loss of positive or negative position on x planer is not lost.
                  x_scale = 0.000001;
                }else if(prevent_loss_of_precision_during_useage_of_zero == 0)
                {
                  x_scale = handle_of_model_within_userland_space["scale"]["x"];
                }
                
              
                vertex_and_colorvalues_data[vertex_and_colorvalues_data_index] = (vertex_and_colorvalues_data[vertex_and_colorvalues_data_index] * x_scale);
                
                //iterate to next starting section of block.
                vertex_and_colorvalues_data_index = vertex_and_colorvalues_data_index + 7;
               
                //stop loop?
                if(vertex_and_colorvalues_data_index >= vertex_and_colorvalues_data.length)
                {
                  //stop
                  continue_applying_scale = 0;
                }
              }
            }
            
          
          //Apply position.
            //
            
          //buffer initalization
            //create a buffer that will sustain during the drawing of frame.
            let vertex_and_colorvalues_buffer = interface_to_opengles.createBuffer();
            
            //keep buffer alive within the GPU by keeping the handle available to be used within the CPU.
            drawscreenloop_intrim_array_of_buffers.push(vertex_and_colorvalues_buffer);
            
            //define buffer data interpretation type.
            interface_to_opengles.bindBuffer(interface_to_opengles.ARRAY_BUFFER, vertex_and_colorvalues_buffer);
            
            //upload vertex and color values to buffer.
            interface_to_opengles.bufferData(interface_to_opengles.ARRAY_BUFFER, vertex_and_colorvalues_data, interface_to_opengles.STATIC_DRAW);
            
            //Signal OpenGL hardware that this is position and color dara and their respective sizes.
            vertex_and_colorvalues_buffer.positionSize = 3;
            vertex_and_colorvalues_buffer.colorSize = 4;
            
            //Signal OpenGL hardware how many groups of XYZ RGBA there are.
            vertex_and_colorvalues_buffer.numberOfItems = 3;
            
            //Bind buffer again to signal to opengl hardware that changes have been made to the ram/cpu variables pertaining this GPU buffer.
            //this step was only needed some of the time during the creation of test scripts, to my point this bindbuffer may not be required.
            interface_to_opengles.bindBuffer(interface_to_opengles.ARRAY_BUFFER, vertex_and_colorvalues_buffer);
            
          //Draw this model
          //Set the shader program to use for the following vertex or vertices and its defineable attributes.
            //Pop in a shader program to be used within the following order of operations.
            let shader_program = list_of_shaders[handle_of_model_within_userland_space["name_of_shader_program"]];
            
            interface_to_opengles.useProgram(shader_program);
           
            //Define the assembly level GPU data transfer and processing line of "vertex position attribute" to be associated with the defined logical programming set within the result of position_of_vertex_to_colorize of the shader program.
            shader_program.vertexPositionAttribute = interface_to_opengles.getAttribLocation(shader_program, "position_of_vertex_to_colorize");
          
            //Define the assembly level GPU data transfer and processing line of "vertex color attribute" to be associated with the defined logical programming set within the result of color_of_vertex_to_colorize of the shader program.
            shader_program.vertexColorAttribute = interface_to_opengles.getAttribLocation(shader_program, "color_of_vertex_to_colorize");
          
           //tell the GPU data line to get ready to transfer position data.
           interface_to_opengles.vertexAttribPointer(shader_program.vertexPositionAttribute,  vertex_and_colorvalues_buffer.positionSize, interface_to_opengles.FLOAT, false, 28, 0);
        
           //tell the GPU data line to get ready to transfer color data.
           interface_to_opengles.vertexAttribPointer(shader_program.vertexColorAttribute,  vertex_and_colorvalues_buffer.colorSize, interface_to_opengles.FLOAT, false, 28, 12);
        
           //tell the gpu you have decided what to transfer and that it is about to happen.
           interface_to_opengles.enableVertexAttribArray(shader_program.vertexPositionAttribute);
      
           //tell the gpu you have decided what to transfer and that it is about to happen.
           interface_to_opengles.enableVertexAttribArray(shader_program.vertexColorAttribute);
        
           //tell the gpu to start the transfer which also trigger the draw after the transfer has completed.
           interface_to_opengles.drawArrays(interface_to_opengles.TRIANGLES, 0, vertex_and_colorvalues_buffer.numberOfItems);
      
        }
      
      //clear list of models to render.
      drawscreenloop_render_selection = [];
      
      //Draw Screen Loop set syncronized timestamp.
      drawscreenloop_render_syncronized_timestamp = Date.now();
      
		}
		
    /* Coordinated Space */
    coordinated_space_convert_xyz_to_opengl_viewport_xyz = function(coordinated_space_x, coordinated_space_y, coordinated_space_z)
    {
      let output = {};
          output["x"] = 0.000000;
          output["y"] = 0.000000;
          output["z"] = 0.000000;
          
      //convert coordinated space x to opengl viewport x
      if(coordinated_space_x > coordinated_space["center_of_x_plane_hatchmarks"])
      {
        let coordinated_space_x_to_opengl_x = (coordinated_space_x - coordinated_space["center_of_x_plane_hatchmarks"]);
        output["x"] = coordinated_space_x_to_opengl_x;
      }else if(coordinated_space_x < coordinated_space["center_of_x_plane_hatchmarks"])
      {
        let coordinated_space_x_to_opengl_x =  (0 - (coordinated_space["center_of_x_plane_hatchmarks"] - coordinated_space_x));
        output["x"] = coordinated_space_x_to_opengl_x;
      }else if(coordinated_space_x == coordinated_space["center_of_x_plane_hatchmarks"])
      {
        output["x"] = 0;
      }
    
      //convert coordinated space y to opengl viewport y.
      if(coordinated_space_y > coordinated_space["center_of_y_plane_hatchmarks"])
      {
        let coordinated_space_y_to_opengl_y = (coordinated_space_y - coordinated_space["center_of_y_plane_hatchmarks"]);
        output["y"] = coordinated_space_y_to_opengl_y;
      }else if(coordinated_space_y < coordinated_space["center_of_y_plane_hatchmarks"])
      {
        let coordinated_space_y_to_opengl_y =  (0 - (coordinated_space["center_of_y_plane_hatchmarks"] - coordinated_space_y));
        output["y"] = coordinated_space_y_to_opengl_y;
      }else if(coordinated_space_y == coordinated_space["center_of_y_plane_hatchmarks"])
      {
        output["y"] = 0;
      }
      
      //convert coordinated space z to opengl viewport z.
      if(coordinated_space_z > coordinated_space["center_of_z_plane_hatchmarks"])
      {
        let coordinated_space_z_to_opengl_z = (coordinated_space_z - coordinated_space["center_of_z_plane_hatchmarks"]);
        output["z"] = coordinated_space_z_to_opengl_z;
      }else if(coordinated_space_z < coordinated_space["center_of_z_plane_hatchmarks"])
      {
        let coordinated_space_z_to_opengl_z =  (0 - (coordinated_space["center_of_z_plane_hatchmarks"] - coordinated_space_z));
        output["z"] = coordinated_space_z_to_opengl_z;
      }else if(coordinated_space_z == coordinated_space["center_of_z_plane_hatchmarks"])
      {
        output["z"] = 0;
      }
          
      return output;
    }
    
    /* Begin startup stages */
    begin_startup = function()
    {
			//start up
      stage_one();
      stage_two();
      //end of starting up stages
			
			//begin course of actions loop
			course_of_actions_loop();
    }
		
		
   
  </script>
</head>
<body onLoad="begin_startup()">
  <canvas id="canvas_for_opengl"></canvas>
</body>
</html>
